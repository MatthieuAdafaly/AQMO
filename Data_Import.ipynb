{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00476433-40ee-4af9-a512-a611e0ab3559",
   "metadata": {},
   "source": [
    "Author: Adafaly Matthieu </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766afbaa-19cf-463f-865c-ce201c267c38",
   "metadata": {},
   "source": [
    "### To use this notebook, simply run it. The necessary data will be automatically downloaded and placed in a folder named Data — create this folder if it does not already exist.\n",
    "### You do not need to extract any files — the Data Import notebook is designed to process them directly.\n",
    "### You only need to run this notebook once. It will generate a dataset that can be used in the other notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f3a16-c9d9-4dfa-a6bf-044bb8718e84",
   "metadata": {},
   "source": [
    "# Importation of the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04805837-ba1f-4bef-bf4c-1d00acb21934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import glob\n",
    "import zipfile\n",
    "import json\n",
    "from rudi_node_read.rudi_node_reader import RudiNodeReader\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05521dc3-51bf-4638-8691-64ba7a4f850c",
   "metadata": {},
   "source": [
    "# Data Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e72713-762c-44b2-8eda-e22e40b5fd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media for metadata '1d67d073-b831-4206-b673-aa9a47978a44': {'downloaded': [{'media_name': 'dump_dev_aqmoinfra_data_2020_08_01-00h00to2020_09_01-00h00.json.zip', 'media_id': '22682787-348f-4b4b-9bcc-0bc37e373bec', 'media_url': 'https://opendata.fenix.rudi-univ-rennes1.fr/storage/download/22682787-348f-4b4b-9bcc-0bc37e373bec', 'file_type': 'application/zip', 'created': '2025-05-19T08:59:04.769Z', 'updated': '2025-05-19T08:59:04.769Z', 'file_path': '/udd/madafaly/Projet pollution/Projet/Data/dump_dev_aqmoinfra_data_2020_08_01-00h00to2020_09_01-00h00.json.zip'}, {'media_name': 'dump_dev_aqmoinfra_data_2020_12_01-00h00to2021_01_01-00h00.json.zip', 'media_id': 'c4609776-3097-4e58-9a0b-157a79a767c0', 'media_url': 'https://opendata.fenix.rudi-univ-rennes1.fr/storage/download/c4609776-3097-4e58-9a0b-157a79a767c0', 'file_type': 'application/zip', 'created': '2025-05-19T08:58:49.447Z', 'updated': '2025-05-19T08:58:49.447Z', 'file_path': '/udd/madafaly/Projet pollution/Projet/Data/dump_dev_aqmoinfra_data_2020_12_01-00h00to2021_01_01-00h00.json.zip'}, {'media_name': 'dump_dev_aqmoinfra_data_2020_04_01-00h00to2020_05_01-00h00.json.zip', 'media_id': '42547d6a-736c-429e-972d-355a971707d1', 'media_url': 'https://opendata.fenix.rudi-univ-rennes1.fr/storage/download/42547d6a-736c-429e-972d-355a971707d1', 'file_type': 'application/zip', 'created': '2025-05-19T08:59:13.428Z', 'updated': '2025-05-19T08:59:13.428Z', 'file_path': '/udd/madafaly/Projet pollution/Projet/Data/dump_dev_aqmoinfra_data_2020_04_01-00h00to2020_05_01-00h00.json.zip'}, {'media_name': 'dump_dev_aqmoinfra_data_2020_06_01-00h00to2020_07_01-00h00.json.zip', 'media_id': '26a78e18-f093-4d66-9cba-d91a122759ad', 'media_url': 'https://opendata.fenix.rudi-univ-rennes1.fr/storage/download/26a78e18-f093-4d66-9cba-d91a122759ad', 'file_type': 'application/zip', 'created': '2025-05-19T08:59:08.897Z', 'updated': '2025-05-19T08:59:08.897Z', 'file_path': '/udd/madafaly/Projet pollution/Projet/Data/dump_dev_aqmoinfra_data_2020_06_01-00h00to2020_07_01-00h00.json.zip'}, {'media_name': 'dump_dev_aqmoinfra_data_2020_05_01-00h00to2020_06_01-00h00.json.zip', 'media_id': 'd090f2d5-1c86-48bd-991b-46c1a76e2f0e', 'media_url': 'https://opendata.fenix.rudi-univ-rennes1.fr/storage/download/d090f2d5-1c86-48bd-991b-46c1a76e2f0e', 'file_type': 'application/zip', 'created': '2025-05-19T08:59:11.380Z', 'updated': '2025-05-19T08:59:11.380Z', 'file_path': '/udd/madafaly/Projet pollution/Projet/Data/dump_dev_aqmoinfra_data_2020_05_01-00h00to2020_06_01-00h00.json.zip'}, {'media_name': 'dump_dev_aqmoinfra_data_2020_11_01-00h00to2020_12_01-00h00.json.zip', 'media_id': '96d6ebd8-fd73-4a0e-97fa-059973508801', 'media_url': 'https://opendata.fenix.rudi-univ-rennes1.fr/storage/download/96d6ebd8-fd73-4a0e-97fa-059973508801', 'file_type': 'application/zip', 'created': '2025-05-19T08:58:58.603Z', 'updated': '2025-05-19T08:58:58.603Z', 'file_path': '/udd/madafaly/Projet pollution/Projet/Data/dump_dev_aqmoinfra_data_2020_11_01-00h00to2020_12_01-00h00.json.zip'}, {'media_name': 'dump_dev_aqmoinfra_data_2020_10_01-00h00to2020_11_01-00h00.json.zip', 'media_id': 'e90b23f1-5fe0-4d25-8d08-7bc88a06df3a', 'media_url': 'https://opendata.fenix.rudi-univ-rennes1.fr/storage/download/e90b23f1-5fe0-4d25-8d08-7bc88a06df3a', 'file_type': 'application/zip', 'created': '2025-05-19T08:59:00.894Z', 'updated': '2025-05-19T08:59:00.894Z', 'file_path': '/udd/madafaly/Projet pollution/Projet/Data/dump_dev_aqmoinfra_data_2020_10_01-00h00to2020_11_01-00h00.json.zip'}, {'media_name': 'dump_dev_aqmoinfra_data_2020_07_01-00h00to2020_08_01-00h00.json.zip', 'media_id': '3272a000-aaf9-447f-a065-ea17332cb766', 'media_url': 'https://opendata.fenix.rudi-univ-rennes1.fr/storage/download/3272a000-aaf9-447f-a065-ea17332cb766', 'file_type': 'application/zip', 'created': '2025-05-19T08:59:06.862Z', 'updated': '2025-05-19T08:59:06.862Z', 'file_path': '/udd/madafaly/Projet pollution/Projet/Data/dump_dev_aqmoinfra_data_2020_07_01-00h00to2020_08_01-00h00.json.zip'}, {'media_name': 'dump_dev_aqmoinfra_data_2020_09_01-00h00to2020_10_01-00h00.json.zip', 'media_id': '2b2ae028-bbac-4b5b-8006-46f7debc1961', 'media_url': 'https://opendata.fenix.rudi-univ-rennes1.fr/storage/download/2b2ae028-bbac-4b5b-8006-46f7debc1961', 'file_type': 'application/zip', 'created': '2025-05-19T08:59:02.511Z', 'updated': '2025-05-19T08:59:02.511Z', 'file_path': '/udd/madafaly/Projet pollution/Projet/Data/dump_dev_aqmoinfra_data_2020_09_01-00h00to2020_10_01-00h00.json.zip'}], 'missing': [], 'skipped': []}\n"
     ]
    }
   ],
   "source": [
    "rudi_node_url = 'https://opendata.fenix.rudi-univ-rennes1.fr'\n",
    "rudi_node_info = RudiNodeReader(server_url=rudi_node_url)\n",
    "meta_id ='1d67d073-b831-4206-b673-aa9a47978a44'\n",
    "dwnld_tag = 'Downloading'\n",
    "dwnld_dir = './Data'\n",
    "print(dwnld_tag, f\"media for metadata '{meta_id}':\", rudi_node_info.download_files_for_metadata(meta_id, dwnld_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d75fa2f-bc83-4c2e-861c-46ee2990bf86",
   "metadata": {},
   "source": [
    "# Concatenation of the data (This process may take several minutes.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e107187-719c-4d93-83b2-8679cd541c35",
   "metadata": {},
   "source": [
    "This code allow to concatenate fson file which are in the repertory Data where the AQMo data stand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa8f4b93-662a-4380-b891-f59417159579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.54s/it]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.67s/it]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:22<00:00, 11.27s/it]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.88s/it]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.53s/it]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:20<00:00, 10.02s/it]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:05<00:00,  2.82s/it]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.98s/it]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:20<00:00, 10.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End\n"
     ]
    }
   ],
   "source": [
    "# Get all .json.zip files in the Data directory\n",
    "files = glob.glob('Data/*.json.zip')\n",
    "merged_data = []\n",
    "for file in files:\n",
    "    with zipfile.ZipFile(file, 'r') as archive:\n",
    "        for name in tqdm(archive.namelist()):\n",
    "            # Ignore macOS metadata files\n",
    "            if name.startswith('__MACOSX/') or os.path.basename(name).startswith('._'):\n",
    "                continue\n",
    "\n",
    "            with archive.open(name) as f:\n",
    "                try:\n",
    "                    content = f.read().decode('utf-8').strip()\n",
    "                    if not content:\n",
    "                        print(f\"⚠️ Empty file in {file} : {name}\")\n",
    "                        continue\n",
    "                    data = json.loads(content)\n",
    "                    merged_data.append(data)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"❌ JSON format error in {file} > {name} : {e}\")\n",
    "                except UnicodeDecodeError as e:\n",
    "                    print(f\"❌ Encoding error in {file} > {name} : {e}\")\n",
    "# Write merged data to a single JSON file\n",
    "with open('./Data/merged_data.json', 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(merged_data, outfile, ensure_ascii=False, indent=2)\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc5b311-339f-4d9f-9833-e35a16ee09f8",
   "metadata": {},
   "source": [
    "# Creation of the clean dataframe for visualisation (This process may take several minutes.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b03525-75b8-4ef7-8559-b0ec7fa7c8b3",
   "metadata": {},
   "source": [
    "Formatting of the data of the dataframe create just before. This new dataframe will be a pickle one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71e1270-7ea3-4fd8-b44f-5b89a414571b",
   "metadata": {},
   "source": [
    "Creation of all hourly variables to facilitate the following analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9ae3993-df80-40ef-9040-ba59b0ded783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [04:01<00:00, 34.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End\n"
     ]
    }
   ],
   "source": [
    "# Load the merged JSON data create just before into a DataFrame\n",
    "df = pd.read_json(\"Data/merged_data.json\")\n",
    "\n",
    "# Extract the 'features' column, which contains nested structures\n",
    "data = df['features']\n",
    "\n",
    "merged_list = []\n",
    "# List of column names that will later be used to extract values\n",
    "columns = ['OPC_N3:04', 'OPC_N3:12', 'OPC_N3:05', 'OPC_N3:16', 'OPC_N3:01', \n",
    "           'OPC_N3:03', 'OPC_N3:09', 'OPC_N3:17', 'OPC_N3:14', 'OPC_N3:20']\n",
    "\n",
    "# Flatten all elements inside the 'features' lists into a single list\n",
    "for row in data:\n",
    "    merged_list.extend(row)\n",
    "\n",
    "# Convert the flattened list of feature dictionaries into a DataFrame\n",
    "df = pd.DataFrame(merged_list)\n",
    "\n",
    "# Normalize nested fields from each feature (like _id, geometry, properties)\n",
    "df_conc = pd.concat([\n",
    "    pd.json_normalize(df[\"_id\"]).rename(columns={\"$oid\": \"id\"}),  # Extract _id field\n",
    "    pd.json_normalize(df[\"geometry\"]).rename(columns={\"type\": \"geo_type\", \"coordinates\": \"geo_coords\"}),  # Extract geometry\n",
    "    pd.json_normalize(df[\"properties\"])  # Extract properties\n",
    "], axis=1)\n",
    "\n",
    "# Function to extract the first non-empty list or value from a predefined list of columns\n",
    "def get_non_na_value(row):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    row: A row of the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    The first non-empty list or non-NaN value found in the specified columns.\n",
    "    Returns NaN if all values are empty or NaN.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        cell = row[col]\n",
    "        if isinstance(cell, list) and cell:  # If it's a non-empty list\n",
    "            return cell\n",
    "        elif pd.notna(cell):  # If it's a non-null value\n",
    "            return cell\n",
    "    return np.nan  # Return NaN if no valid value is found\n",
    "# Apply the function to each row to get a representative value and store it in a new column\n",
    "df_conc['concatenated_values'] = df_conc.apply(get_non_na_value, axis=1)\n",
    "\n",
    "# Function to extract the value of a specified key from a list of dictionaries\n",
    "def extract_value(opc_list, key):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    opc_list (list): A list of dictionaries containing sensor data.\n",
    "    key: The key to extract the value for (['p', 'bu', 'dc', 'SDN:L20', 'v', 't', 'bn').\n",
    "\n",
    "    Returns:\n",
    "    The value associated with the key from the first dictionary where the key exists.\n",
    "    Returns None if the key is not found in any dictionary.\n",
    "    \"\"\"\n",
    "    if isinstance(opc_list, list):\n",
    "        for item in opc_list:\n",
    "            if key in item:\n",
    "                return item[key]\n",
    "    return None\n",
    "# List of keys to extract from the 'concatenated_values' column\n",
    "keys = ['p', 'bu', 'dc', 'SDN:L20', 'v', 't', 'bn']\n",
    "# For each key, create a new column in the DataFrame by extracting values from the 'concatenated_values' column\n",
    "for key in tqdm(keys):\n",
    "    col_name = f\"{key}\"\n",
    "    df_conc[col_name] = df_conc.apply(\n",
    "        lambda row: extract_value(row['concatenated_values'], key) \n",
    "                    if pd.isna(row.get(col_name)) else row[col_name], axis=1)\n",
    "# Extract latitude and longitude from 'geo_coords' only if the geometry type is 'Point'\n",
    "df_conc.loc[df_conc['geo_type'] == 'Point', 'longitude'] = df_conc['geo_coords'].apply(\n",
    "    lambda x: x[0] if isinstance(x, list) else None)\n",
    "df_conc.loc[df_conc['geo_type'] == 'Point', 'latitude'] = df_conc['geo_coords'].apply(\n",
    "    lambda x: x[1] if isinstance(x, list) else None)\n",
    "# Extract latitude and longitude from 'geo_coords' only if the geometry type is 'LineString'\n",
    "df_conc.loc[df_conc['geo_type'] == 'LineString', 'longitude'] = df_conc['geo_coords'].apply(\n",
    "    lambda x: sum(coord[0] for coord in x) / len(x) if isinstance(x, list) and all(isinstance(coord, list) for coord in x) else None)\n",
    "df_conc.loc[df_conc['geo_type'] == 'LineString', 'latitude'] = df_conc['geo_coords'].apply(\n",
    "    lambda x: sum(coord[1] for coord in x) / len(x) if isinstance(x, list) and all(isinstance(coord, list) for coord in x) else None)\n",
    "# Convert date strings to datetime objects\n",
    "df_conc[\"station.date\"] = pd.to_datetime(df_conc[\"station.date\"], errors='coerce')\n",
    "df_conc[\"station.from_date\"] = pd.to_datetime(df_conc[\"station.from_date\"], errors='coerce')\n",
    "print(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94c90d6f-dbf7-448f-ab10-cbeea26f7a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>geo_type</th>\n",
       "      <th>geo_coords</th>\n",
       "      <th>station.name</th>\n",
       "      <th>station.date</th>\n",
       "      <th>station.from_date</th>\n",
       "      <th>station.radius</th>\n",
       "      <th>station.policy</th>\n",
       "      <th>OPC_N3:12</th>\n",
       "      <th>OPC_N3:04</th>\n",
       "      <th>...</th>\n",
       "      <th>concatenated_values</th>\n",
       "      <th>p</th>\n",
       "      <th>bu</th>\n",
       "      <th>dc</th>\n",
       "      <th>SDN:L20</th>\n",
       "      <th>v</th>\n",
       "      <th>t</th>\n",
       "      <th>bn</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5f4dd4a08138160014a73e49</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-1.643674109, 48.110235135]</td>\n",
       "      <td>parautarin02</td>\n",
       "      <td>2020-08-31 17:16:47+00:00</td>\n",
       "      <td>2020-08-31 17:16:47+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>mobileGps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.643674</td>\n",
       "      <td>48.110235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5f4dd4b88138160014a73e51</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-1.643674109, 48.110235135]</td>\n",
       "      <td>parautarin02</td>\n",
       "      <td>2020-08-31 17:16:47+00:00</td>\n",
       "      <td>2020-08-31 17:16:47+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>mobileGps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.643674</td>\n",
       "      <td>48.110235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5f4dd4b88138160014a73e52</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-1.643674109, 48.110235135]</td>\n",
       "      <td>parautarin02</td>\n",
       "      <td>2020-08-31 17:16:47+00:00</td>\n",
       "      <td>2020-08-31 17:16:47+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>mobileGps</td>\n",
       "      <td>[{'bn': 'OPC_N3:12', 'bu': 'ug/m3', 'dc': 0}, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'bn': 'OPC_N3:12', 'bu': 'ug/m3', 'dc': 0}, ...</td>\n",
       "      <td>24.226</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2020-09-01 04:57:28 UTC</td>\n",
       "      <td>OPC_N3:12</td>\n",
       "      <td>-1.643674</td>\n",
       "      <td>48.110235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5f4dd4e68138160014a73e5e</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-1.643674109, 48.110235135]</td>\n",
       "      <td>parautarin02</td>\n",
       "      <td>2020-08-31 17:16:47+00:00</td>\n",
       "      <td>2020-08-31 17:16:47+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>mobileGps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.643674</td>\n",
       "      <td>48.110235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5f4dd8108138160014a73fdd</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-1.643601215, 48.110021621]</td>\n",
       "      <td>parautarin33</td>\n",
       "      <td>2020-08-31 17:07:05+00:00</td>\n",
       "      <td>2020-08-31 17:07:05+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>mobileGps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.643601</td>\n",
       "      <td>48.110022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808114</th>\n",
       "      <td>5f4dd56a8138160014a73e96</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-1.643686376, 48.110172833]</td>\n",
       "      <td>parautarin02</td>\n",
       "      <td>2020-09-01 03:00:25+00:00</td>\n",
       "      <td>2020-09-01 03:00:25+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>mobileGps</td>\n",
       "      <td>[{'bn': 'OPC_N3:12', 'bu': 'ug/m3', 'dc': 0}, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'bn': 'OPC_N3:12', 'bu': 'ug/m3', 'dc': 0}, ...</td>\n",
       "      <td>44.083</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2020-09-01 05:00:26 UTC</td>\n",
       "      <td>OPC_N3:12</td>\n",
       "      <td>-1.643686</td>\n",
       "      <td>48.110173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808115</th>\n",
       "      <td>5f4dd56a8138160014a73e97</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-1.643686376, 48.110172833]</td>\n",
       "      <td>parautarin02</td>\n",
       "      <td>2020-09-01 03:00:25+00:00</td>\n",
       "      <td>2020-09-01 03:00:25+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>mobileGps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.643686</td>\n",
       "      <td>48.110173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808116</th>\n",
       "      <td>5f4dd53e8138160014a73e80</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-1.643686376, 48.110172833]</td>\n",
       "      <td>parautarin02</td>\n",
       "      <td>2020-09-01 02:59:40+00:00</td>\n",
       "      <td>2020-09-01 02:59:40+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>mobileGps</td>\n",
       "      <td>[{'bn': 'OPC_N3:12', 'bu': 'ug/m3', 'dc': 0}, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'bn': 'OPC_N3:12', 'bu': 'ug/m3', 'dc': 0}, ...</td>\n",
       "      <td>44.259</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2020-09-01 04:59:42 UTC</td>\n",
       "      <td>OPC_N3:12</td>\n",
       "      <td>-1.643686</td>\n",
       "      <td>48.110173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808117</th>\n",
       "      <td>5f4dd53e8138160014a73e81</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-1.643686376, 48.110172833]</td>\n",
       "      <td>parautarin02</td>\n",
       "      <td>2020-09-01 02:59:40+00:00</td>\n",
       "      <td>2020-09-01 02:59:40+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>mobileGps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.643686</td>\n",
       "      <td>48.110173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808118</th>\n",
       "      <td>5f4dd5128138160014a73e6b</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-1.643672568, 48.110166333]</td>\n",
       "      <td>parautarin02</td>\n",
       "      <td>2020-09-01 02:58:55+00:00</td>\n",
       "      <td>2020-09-01 02:58:55+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>mobileGps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.643673</td>\n",
       "      <td>48.110166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2808119 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id geo_type                    geo_coords  \\\n",
       "0        5f4dd4a08138160014a73e49    Point  [-1.643674109, 48.110235135]   \n",
       "1        5f4dd4b88138160014a73e51    Point  [-1.643674109, 48.110235135]   \n",
       "2        5f4dd4b88138160014a73e52    Point  [-1.643674109, 48.110235135]   \n",
       "3        5f4dd4e68138160014a73e5e    Point  [-1.643674109, 48.110235135]   \n",
       "4        5f4dd8108138160014a73fdd    Point  [-1.643601215, 48.110021621]   \n",
       "...                           ...      ...                           ...   \n",
       "2808114  5f4dd56a8138160014a73e96    Point  [-1.643686376, 48.110172833]   \n",
       "2808115  5f4dd56a8138160014a73e97    Point  [-1.643686376, 48.110172833]   \n",
       "2808116  5f4dd53e8138160014a73e80    Point  [-1.643686376, 48.110172833]   \n",
       "2808117  5f4dd53e8138160014a73e81    Point  [-1.643686376, 48.110172833]   \n",
       "2808118  5f4dd5128138160014a73e6b    Point  [-1.643672568, 48.110166333]   \n",
       "\n",
       "         station.name              station.date         station.from_date  \\\n",
       "0        parautarin02 2020-08-31 17:16:47+00:00 2020-08-31 17:16:47+00:00   \n",
       "1        parautarin02 2020-08-31 17:16:47+00:00 2020-08-31 17:16:47+00:00   \n",
       "2        parautarin02 2020-08-31 17:16:47+00:00 2020-08-31 17:16:47+00:00   \n",
       "3        parautarin02 2020-08-31 17:16:47+00:00 2020-08-31 17:16:47+00:00   \n",
       "4        parautarin33 2020-08-31 17:07:05+00:00 2020-08-31 17:07:05+00:00   \n",
       "...               ...                       ...                       ...   \n",
       "2808114  parautarin02 2020-09-01 03:00:25+00:00 2020-09-01 03:00:25+00:00   \n",
       "2808115  parautarin02 2020-09-01 03:00:25+00:00 2020-09-01 03:00:25+00:00   \n",
       "2808116  parautarin02 2020-09-01 02:59:40+00:00 2020-09-01 02:59:40+00:00   \n",
       "2808117  parautarin02 2020-09-01 02:59:40+00:00 2020-09-01 02:59:40+00:00   \n",
       "2808118  parautarin02 2020-09-01 02:58:55+00:00 2020-09-01 02:58:55+00:00   \n",
       "\n",
       "         station.radius station.policy  \\\n",
       "0                     0      mobileGps   \n",
       "1                     0      mobileGps   \n",
       "2                     0      mobileGps   \n",
       "3                     0      mobileGps   \n",
       "4                     0      mobileGps   \n",
       "...                 ...            ...   \n",
       "2808114               0      mobileGps   \n",
       "2808115               0      mobileGps   \n",
       "2808116               0      mobileGps   \n",
       "2808117               0      mobileGps   \n",
       "2808118               0      mobileGps   \n",
       "\n",
       "                                                 OPC_N3:12 OPC_N3:04  ...  \\\n",
       "0                                                      NaN       NaN  ...   \n",
       "1                                                      NaN       NaN  ...   \n",
       "2        [{'bn': 'OPC_N3:12', 'bu': 'ug/m3', 'dc': 0}, ...       NaN  ...   \n",
       "3                                                      NaN       NaN  ...   \n",
       "4                                                      NaN       NaN  ...   \n",
       "...                                                    ...       ...  ...   \n",
       "2808114  [{'bn': 'OPC_N3:12', 'bu': 'ug/m3', 'dc': 0}, ...       NaN  ...   \n",
       "2808115                                                NaN       NaN  ...   \n",
       "2808116  [{'bn': 'OPC_N3:12', 'bu': 'ug/m3', 'dc': 0}, ...       NaN  ...   \n",
       "2808117                                                NaN       NaN  ...   \n",
       "2808118                                                NaN       NaN  ...   \n",
       "\n",
       "                                       concatenated_values       p     bu  \\\n",
       "0                                                      NaN     NaN   None   \n",
       "1                                                      NaN     NaN   None   \n",
       "2        [{'bn': 'OPC_N3:12', 'bu': 'ug/m3', 'dc': 0}, ...  24.226  ug/m3   \n",
       "3                                                      NaN     NaN   None   \n",
       "4                                                      NaN     NaN   None   \n",
       "...                                                    ...     ...    ...   \n",
       "2808114  [{'bn': 'OPC_N3:12', 'bu': 'ug/m3', 'dc': 0}, ...  44.083  ug/m3   \n",
       "2808115                                                NaN     NaN   None   \n",
       "2808116  [{'bn': 'OPC_N3:12', 'bu': 'ug/m3', 'dc': 0}, ...  44.259  ug/m3   \n",
       "2808117                                                NaN     NaN   None   \n",
       "2808118                                                NaN     NaN   None   \n",
       "\n",
       "          dc SDN:L20     v                        t         bn longitude  \\\n",
       "0        NaN     NaN   NaN                     None       None -1.643674   \n",
       "1        NaN     NaN   NaN                     None       None -1.643674   \n",
       "2        0.0     0.0  1.61  2020-09-01 04:57:28 UTC  OPC_N3:12 -1.643674   \n",
       "3        NaN     NaN   NaN                     None       None -1.643674   \n",
       "4        NaN     NaN   NaN                     None       None -1.643601   \n",
       "...      ...     ...   ...                      ...        ...       ...   \n",
       "2808114  0.0     0.0  2.00  2020-09-01 05:00:26 UTC  OPC_N3:12 -1.643686   \n",
       "2808115  NaN     NaN   NaN                     None       None -1.643686   \n",
       "2808116  0.0     0.0  2.35  2020-09-01 04:59:42 UTC  OPC_N3:12 -1.643686   \n",
       "2808117  NaN     NaN   NaN                     None       None -1.643686   \n",
       "2808118  NaN     NaN   NaN                     None       None -1.643673   \n",
       "\n",
       "          latitude  \n",
       "0        48.110235  \n",
       "1        48.110235  \n",
       "2        48.110235  \n",
       "3        48.110235  \n",
       "4        48.110022  \n",
       "...            ...  \n",
       "2808114  48.110173  \n",
       "2808115  48.110173  \n",
       "2808116  48.110173  \n",
       "2808117  48.110173  \n",
       "2808118  48.110166  \n",
       "\n",
       "[2808119 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c65723f7-369b-4d3d-a404-e58c5bd69ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean=df_conc\n",
    "df_clean[\"day_week\"] = df_clean[\"station.date\"].dt.day_name()\n",
    "df_clean['day'] = df_clean['station.date'].dt.day\n",
    "df_clean['hour'] = df_clean['station.date'].dt.hour\n",
    "df_clean['month'] = df_clean['station.date'].dt.month\n",
    "df_clean['year'] = df_clean['station.date'].dt.year\n",
    "df_clean['hour_minute_second'] = df_clean['station.date'].dt.strftime('%H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17a4408-97e1-49a2-8476-d0469b81c26a",
   "metadata": {},
   "source": [
    "We remove duplicate or unnecessary variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d49a42-80c5-4f08-941d-8194b5d29fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.drop(columns=[\"bu\",'dc','SDN:L20','concatenated_values','t','station.radius'])\n",
    "df_clean = df_clean.drop(columns=df_clean.filter(like='OPC').columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64df26c-79d1-495e-981d-103220fb3430",
   "metadata": {},
   "source": [
    "First, we remove the sensor 'parautarin 36' because it recorded only one measurement that had associated pollution values. Then, we remove the sensor 'standalone-LOPY-AQ05' because it has the same issue(not enough value). Finally, we drop the fixed measurement from the 'parautarin35' sensor, which is normally a mobile one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9349d2b6-4606-44a3-b792-5cd687b8ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[~df_clean['station.name'].isin(['parautarin36'])]\n",
    "df_clean = df_clean[~df_clean['station.name'].isin(['standalone-LOPY-AQ05'])]\n",
    "df_clean = df_clean[~((df_clean['station.name'] == 'parautarin35') & (df_clean['station.policy'] == 'fixedGps'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef8218d-1659-4365-aa90-a50914b701b0",
   "metadata": {},
   "source": [
    "We rename the variables to improve clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "018abb7f-32b5-4b1c-9ebc-f8445fa48f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.rename(columns={\"v\": \"PM_2.5\",\n",
    "    \"station.name\": \"sensor_name\",\n",
    "    \"station.date\": \"measure_date\",\n",
    "    \"station.from_date\": \"start_date\",\n",
    "    \"station.policy\": \"sensor_type\",\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8adf2df-d018-45df-bf06-d91c427e7e16",
   "metadata": {},
   "source": [
    "We explicitly define the data types of each column in the DataFrame to ensure correct data handling and avoid type-related issues during analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1c6bc5f-8168-4960-96d6-2eec357e5a0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display a detailed summary of columns and their data types\n",
    "df_clean = df_clean.astype({\n",
    "    'id': 'string',\n",
    "    'geo_type': 'string',\n",
    "    'bn': 'string',\n",
    "    'sensor_type': 'string',\n",
    "    'day_week': 'string',\n",
    "    'longitude': 'float',\n",
    "    'latitude': 'float',\n",
    "    'hour_minute_second': 'string'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91956eea-a7d5-450e-bb7e-a47226c6c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c268dd-467e-4b70-924d-556571c5543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.replace([\"NaN\",np.nan,None], pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da8c7c8-a6b2-44bd-8a6f-be8acc7e7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.dropna(subset=[\"p\", \"PM_2.5\", \"bn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66422de-bb82-42ea-a94a-cd7af2a95e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.astype({\n",
    "    'PM_2.5': 'float',\n",
    "    'p': 'float',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffae6f39-a0e0-4f4f-9028-cc5ae908633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45400813-fe6d-453b-93d7-7e80ffa6a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.set_index([\"sensor_name\", \"measure_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8ffcc-8dde-4e4f-991c-7012a0d49cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26dd3a-77e0-4d6b-bcbb-be12424ea2a9",
   "metadata": {},
   "source": [
    "This returns all rows whose index appears more than once in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63812634-fd53-4449-9aad-9d8003e90e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated = df_clean.index.duplicated(keep=False)\n",
    "df_clean[duplicated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f5dfe5-9cc0-42be-a291-1e944dd3023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by index and by ascending 'p' values\n",
    "df_sorted = df_clean.sort_values(by=['sensor_name', 'measure_date', 'p'])\n",
    "\n",
    "# Keep the first occurrence for each index (the one with the smallest 'p' comes first)\n",
    "df_unique = df_sorted[~df_sorted.index.duplicated(keep='first')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f18fd3-f8fc-401a-883c-0ff94e198f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df_unique.sort_index(level=\"measure_date\")\n",
    "df_unique = df_unique.sort_index(level=\"sensor_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6744240f-90c7-4700-ab48-6f03642767be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8108e1-0aeb-4503-bf39-debe412715b1",
   "metadata": {},
   "source": [
    "Save the DataFrame as a pickle (.pkl) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e54a51-c441-47f0-b81e-dfaece7c9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.to_pickle('Data/pollution_rennes.pkl')  # Save the complete data\n",
    "print(\"Files loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd2b73-c64f-48e6-ba79-bc86b7221bfe",
   "metadata": {},
   "source": [
    "Save the DataFrame as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ff929-2d61-4ccc-9f28-070b89b339b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV\n",
    "df_unique.to_csv(\"Data/pollution_rennes.csv\", index=True)  # Use index=False to exclude the index as a column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
