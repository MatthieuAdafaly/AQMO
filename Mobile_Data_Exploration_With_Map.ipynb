{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00476433-40ee-4af9-a512-a611e0ab3559",
   "metadata": {},
   "source": [
    "Author: Adafaly Matthieu </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1720ec07-18d2-48ea-8a3b-d0781c343417",
   "metadata": {},
   "source": [
    "# Code Explanation:</br>\n",
    "\n",
    "This code focuses on the data collected from mobile sensors in order to create a map. This map will include several filters (geographical, temporal, etc.) and will allow users to explore the data in more detail for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d877ee-6afe-44f8-91a4-a16825e946e3",
   "metadata": {},
   "source": [
    " This code aim to get the library and to shutdown the warning of the other code part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5883cc34-cc16-4fad-be78-d5d77bbc0921",
   "metadata": {},
   "source": [
    "# Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3616f-f8fe-4b6f-aa66-1ce1f9d937a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkcalendar import Calendar\n",
    "from datetime import datetime, timedelta\n",
    "import folium\n",
    "import json\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "from sklearn.cluster import DBSCAN\n",
    "from folium.plugins import Draw\n",
    "import webbrowser\n",
    "from IPython.display import display, IFrame, Markdown\n",
    "from tkinter import filedialog\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585425c8-24f5-4fcd-8203-026c38ba4791",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108b53c4-2647-4aa2-b48b-822afc2aee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"Data/pollution_rennes.pkl\")\n",
    "print(\"dataframe loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9288dc4-7c0e-4f8a-ba8e-e87450cd6635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mobile = df.loc[(df['sensor_type'] == 'mobileGps') & (df['PM_2.5'].notna())]\n",
    "df_mobile = df_mobile.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3724479-3e75-4495-ac29-63c8147b4d48",
   "metadata": {},
   "source": [
    "# Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1738ff-cc01-440b-9583-fa07fd4e98a3",
   "metadata": {},
   "source": [
    "## Map generation and filter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec29df93-4327-407e-93b7-ab4f61c47e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_point(coords):\n",
    "    \"\"\"\n",
    "    Extracts the first coordinate pair from a list of coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    coords (list): A list of coordinate pairs (long,lat).\n",
    "\n",
    "    Returns:\n",
    "    list or None: A list containing the first longitude and latitude as floats,\n",
    "                  or None if the input is invalid or improperly formatted.\n",
    "    \"\"\"\n",
    "    # Check that the coordinates are a list and contain at least one point\n",
    "    if isinstance(coords, list) and len(coords) > 0:\n",
    "        # Retrieve the first coordinate pair\n",
    "        try:\n",
    "            return [float(coords[0][0]), float(coords[0][1])]  # Longitude, Latitude\n",
    "        except (ValueError, TypeError):\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Apply this function to rows with geometry type 'LineString'\n",
    "df_mobile.loc[df_mobile['geo_type'] == 'LineString', 'longitude'] = df_mobile['geo_coords'].apply(\n",
    "    lambda x: get_first_point(x)[0] if isinstance(x, list) and get_first_point(x) is not None else None\n",
    ")\n",
    "\n",
    "df_mobile.loc[df_mobile['geo_type'] == 'LineString', 'latitude'] = df_mobile['geo_coords'].apply(\n",
    "    lambda x: get_first_point(x)[1] if isinstance(x, list) and get_first_point(x) is not None else None\n",
    ")\n",
    "\n",
    "df = df_mobile\n",
    "\n",
    "# Extract date only (remove timezone) and convert to datetime\n",
    "df['date'] = df['measure_date'].dt.date  \n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Extract time component separately\n",
    "df['time'] = df['measure_date'].dt.time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3380006c-2b3b-45e9-98eb-4f221dc9c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustered = None\n",
    "df_superpose = pd.DataFrame()  # Initialize with empty dataframe or load it with your data\n",
    "\n",
    "def load_geojson_rectangle():\n",
    "    \"\"\"\n",
    "    Opens a file dialog to allow the user to select a GeoJSON file and loads its content.\n",
    "\n",
    "    Returns:\n",
    "    dict or None: The parsed GeoJSON data as a dictionary if a file is selected,\n",
    "                  otherwise None.\n",
    "    \"\"\"\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"GeoJSON files\", \"*.geojson\")])\n",
    "    if not file_path:\n",
    "        print(\"No file selected.\")\n",
    "        return None\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        geojson_data = json.load(f)\n",
    "    return geojson_data\n",
    "\n",
    "\n",
    "\n",
    "def filter_by_rectangle(df, geojson_data) -> pd.DataFrame():\n",
    "    \"\"\"\n",
    "    Filters a DataFrame based on the geographic bounds defined by a GeoJSON rectangle.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data to be filtered.\n",
    "    geojson_data (dict): The GeoJSON data containing the rectangle coordinates for filtering.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A filtered DataFrame containing only the points within the geographic rectangle.\n",
    "                  Returns an empty DataFrame if there is an error or no points match the criteria.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        coords = geojson_data['features'][0]['geometry']['coordinates'][0]\n",
    "        lons = [c[0] for c in coords]\n",
    "        lats = [c[1] for c in coords]\n",
    "\n",
    "        min_lat, max_lat = min(lats), max(lats)\n",
    "        min_lon, max_lon = min(lons), max(lons)\n",
    "\n",
    "        df_filtered = df[\n",
    "            (df['latitude'] >= min_lat) &\n",
    "            (df['latitude'] <= max_lat) &\n",
    "            (df['longitude'] >= min_lon) &\n",
    "            (df['longitude'] <= max_lon)]\n",
    "        \n",
    "\n",
    "        print(f\"{len(df_filtered)} points found in the rectangle.\")\n",
    "        return df_filtered\n",
    "    except Exception as e:\n",
    "        print(\"Error while filtering with the rectangle:\", e)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "def get_color(v) -> str:\n",
    "    \"\"\"\n",
    "    Determines the color based on the pollution value.\n",
    "\n",
    "    Parameters:\n",
    "    v (float): The pollution PM 2.5 value (in µg/m³) of an observation.\n",
    "\n",
    "    Returns:\n",
    "    str: A color corresponding to the pollution level:\n",
    "         - \"green\" for values less than 5 µg/m³,\n",
    "         - \"yellow\" for values between 5 µg/m³ and 15 µg/m³,\n",
    "         - \"orange\" for values between 15 µg/m³ and 25 µg/m³,\n",
    "         - \"red\" for values greater than or equal to 25 µg/m³.\n",
    "    \"\"\"\n",
    "    if v < 5:\n",
    "        return \"green\"\n",
    "    elif v < 15:\n",
    "        return \"yellow\"\n",
    "    elif v < 25:\n",
    "        return \"orange\"\n",
    "    else:\n",
    "        return \"red\"\n",
    "\n",
    "\n",
    "def display_map(start, end, selected_filters) ->  None:\n",
    "    \"\"\"\n",
    "    Return the map with the applied filters\n",
    "\n",
    "    Parameters:\n",
    "    start (date): The first date selected\n",
    "    end (date): The second date selected\n",
    "    selected_filters (list[str]): The selected sensors\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    global df_clustered\n",
    "    global df_superpose  \n",
    "    df_loca['date'] = pd.to_datetime(df_loca['date']).dt.normalize()\n",
    "    filtered = df_loca[(df_loca['date'] >= start) & (df_loca['date'] <= end)].copy()\n",
    "    print(f\"Start Date: {start} \\nEnd Date:   {end}\")\n",
    "    print(f\"Number of points after date filtering: {len(filtered)}\")\n",
    "    filter_dict = {station: filtered[filtered['sensor_name'] == station] for station in filtered['sensor_name'].unique()}\n",
    "    df_superpose =  pd.DataFrame()\n",
    "    print(selected_filters)\n",
    "    for i in selected_filters:\n",
    "        if i in filter_dict:\n",
    "            print(f\"Number of points for {i}: {len(filter_dict[i])}\")\n",
    "            df_superpose = pd.concat([df_superpose, filter_dict[i]], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"[⚠️] Sensor '{i}' has no data in this period or area.\")\n",
    "\n",
    "    print(f\"Filtered sensors: {', '.join(selected_filters)}\")\n",
    "    print(f\"Number of points after sensor filtering: {len(df_superpose)}\")\n",
    "    if len(df_superpose)==0:\n",
    "        m = folium.Map(location=[df_mobile['latitude'].mean(), df_mobile['longitude'].mean()], zoom_start=12)\n",
    "        display(m)\n",
    "    else:\n",
    "        coords = df_superpose[['latitude', 'longitude']].values\n",
    "        db = DBSCAN(eps=0.0002, min_samples=1).fit(coords)\n",
    "        df_superpose.loc[:, 'cluster'] = db.labels_\n",
    "    \n",
    "        df_clustered = df_superpose.groupby('cluster').agg({\n",
    "            'latitude': 'mean', \n",
    "            'longitude': 'mean', \n",
    "            'PM_2.5': 'mean',\n",
    "            'sensor_name': lambda x: ', '.join(x.unique())\n",
    "        }).reset_index()\n",
    "    \n",
    "        m = folium.Map(location=[df['latitude'].mean(), df['longitude'].mean()], zoom_start=12)\n",
    "        low_group = folium.FeatureGroup(name=\"Low (<5 µg/m³)\", overlay=True)\n",
    "        mod_group = folium.FeatureGroup(name=\"Moderate (5-15 µg/m³)\", overlay=True)\n",
    "        high_group = folium.FeatureGroup(name=\"High (15-25 µg/m³)\", overlay=True)\n",
    "        crit_group = folium.FeatureGroup(name=\"Critical (>25 µg/m³)\", overlay=True)\n",
    "    \n",
    "        for _, row in df_clustered.iterrows():\n",
    "            color = get_color(row['PM_2.5'])\n",
    "            marker = folium.CircleMarker(\n",
    "                location=[row['latitude'], row['longitude']],\n",
    "                radius=max(2, min(3, row['PM_2.5'] / 5)),\n",
    "                color=color,\n",
    "                fill=True,\n",
    "                fill_color=color,\n",
    "                fill_opacity=0.7,\n",
    "                popup=f\"Pollution: {round(row['PM_2.5'], 2)} µg/m³ - Station {row['sensor_name']}\"\n",
    "            )\n",
    "    \n",
    "            if row['PM_2.5'] < 5:\n",
    "                low_group.add_child(marker)\n",
    "            elif row['PM_2.5'] < 15:\n",
    "                mod_group.add_child(marker)\n",
    "            elif row['PM_2.5'] < 25:\n",
    "                high_group.add_child(marker)\n",
    "            else:\n",
    "                crit_group.add_child(marker)\n",
    "    \n",
    "        for group in [low_group, mod_group, high_group, crit_group]:\n",
    "            group.add_to(m)\n",
    "    \n",
    "        folium.LayerControl().add_to(m)\n",
    "    \n",
    "        draw = Draw(\n",
    "            export=True,\n",
    "            draw_options={\n",
    "                'polyline': False,\n",
    "                'polygon': False,\n",
    "                'circle': False,\n",
    "                'circlemarker': False,\n",
    "                'marker': False,\n",
    "                'rectangle': True\n",
    "            },\n",
    "            edit_options={'edit': False}\n",
    "        )\n",
    "        draw.add_to(m)\n",
    "    \n",
    "        m.save(\"map_pollution.html\")\n",
    "        \n",
    "        # Open the map\n",
    "        webbrowser.open(\"map_pollution.html\")\n",
    "\n",
    "def request_dates():\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    min_date = df_mobile['date'].min().date()\n",
    "    max_date = df_mobile['date'].max().date()\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Select Dates\")\n",
    "    root.attributes(\"-topmost\", True)\n",
    "\n",
    "    calendar_start = Calendar(root, selectmode='day', date_pattern='yyyy-mm-dd', mindate=min_date, maxdate=max_date)\n",
    "    calendar_start.selection_set(min_date)\n",
    "    calendar_start.pack(pady=10)\n",
    "\n",
    "    calendar_end = Calendar(root, selectmode='day', date_pattern='yyyy-mm-dd', mindate=min_date, maxdate=max_date)\n",
    "    calendar_end.selection_set(max_date)\n",
    "    calendar_end.pack(pady=10)\n",
    "\n",
    "    stations = df['sensor_name'].unique()\n",
    "    filter_vars = {}\n",
    "    \n",
    "    filters_frame = tk.Frame(root)\n",
    "    filters_frame.pack(pady=10)\n",
    "\n",
    "    for station in stations:\n",
    "        filter_vars[station] = tk.BooleanVar(value=True)\n",
    "        tk.Checkbutton(filters_frame, text=station, variable=filter_vars[station]).pack(anchor=tk.W)\n",
    "\n",
    "    def get_dates():\n",
    "        \"\"\"\n",
    "        Retrieves the start and end dates selected by the user from the calendar widgets, adjusts the end date to include the entire day, collects the selected filters, and call the function display map.\n",
    "\n",
    "        Parameters:\n",
    "        None\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        global selected_filters\n",
    "        start_date = calendar_start.get_date()\n",
    "        end_date = calendar_end.get_date()\n",
    "        start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        end_date = datetime.strptime(end_date, \"%Y-%m-%d\") + timedelta(days=1) - timedelta(seconds=1)\n",
    "    \n",
    "        selected_filters = [station for station, filter_var in filter_vars.items() if filter_var.get()]\n",
    "        display_map(start_date, end_date, selected_filters)\n",
    "    \n",
    "    def on_quit():\n",
    "        \"\"\"\n",
    "        Quit the window \n",
    "\n",
    "        Parameters:\n",
    "        None\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        root.destroy()\n",
    "    \n",
    "    def on_load_rectangle():\n",
    "        \"\"\"\n",
    "        Write the number of observation left after applying the location filter\n",
    "                \n",
    "        Parameters:\n",
    "        None\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        global df_loca\n",
    "        # Loads a GeoJSON file and applies filtering\n",
    "        geojson_data = load_geojson_rectangle()  # Loads the GeoJSON file using the previous function\n",
    "        if geojson_data is not None:\n",
    "            # Applies a filter on the DataFrame data based on the GeoJSON\n",
    "            df_loca = filter_by_rectangle(df, geojson_data)\n",
    "            print(f\"Number of points after filtering by rectangle: {len(df_loca)}\")\n",
    "\n",
    "    def on_validate():\n",
    "        \"\"\"\n",
    "        This function select the data frame that will be use in the get dates function.\n",
    "        \n",
    "        Parameters:\n",
    "        None\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        global df_loca\n",
    "        if 'df_loca' in globals():\n",
    "            pass  # It already exists, so do nothing\n",
    "        else:\n",
    "            df_loca = df_mobile\n",
    "        print(f\"Number of points after filtering by rectangle: {len(df_loca)}\")\n",
    "        get_dates()\n",
    "    \n",
    "    button_frame = tk.Frame(root)\n",
    "    button_frame.pack(pady=20)\n",
    "    \n",
    "    load_btn = tk.Button(button_frame, text=\"Load Rectangle\", command=on_load_rectangle)\n",
    "    load_btn.pack(side=tk.LEFT, padx=10)\n",
    "    \n",
    "    quit_btn = tk.Button(button_frame, text=\"Quit\", command=on_quit)\n",
    "    quit_btn.pack(side=tk.LEFT, padx=10)\n",
    "    \n",
    "    quit_btn = tk.Button(button_frame, text=\"Confirm\", command=on_validate)\n",
    "    quit_btn.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "request_dates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66360f31-eecc-451a-b727-bc961ce3c475",
   "metadata": {},
   "source": [
    "## Map Visualizations Based on Active Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0825433b-f20c-4093-8bf0-68318c63d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.renderers.default = 'notebook'  # ou 'iframe', 'notebook_connected'\n",
    "# Average per month\n",
    "df_monthly = df_superpose.groupby('month')['PM_2.5'].mean().reset_index()\n",
    "\n",
    "# Line chart with Plotly\n",
    "fig = px.line(df_monthly,\n",
    "              x='month',\n",
    "              y='PM_2.5',\n",
    "              title=\"Monthly Evolution of Pollution (PM_2.5 in µg/m³)\",\n",
    "              labels={'month': 'Month', 'v (ug/m3)': 'Pollution Value (µg/m³)'})\n",
    "\n",
    "fig.update_layout(template='plotly_white', xaxis_title='Month', yaxis_title='µg/m³')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d855f-614d-4d70-8ed6-d0da0b63ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot with Plotly\n",
    "fig = px.box(df_superpose, \n",
    "             x=\"sensor_name\", \n",
    "             y=\"PM_2.5\", \n",
    "             title=\"Distribution of Pollution Values by Station\", \n",
    "             labels={\"PM_2.5\": \"Pollution Value (µg/m³)\", \"sensor_name\": \"Station Name\"})\n",
    "\n",
    "# Update margins to center the box\n",
    "fig.update_layout(\n",
    "    margin=dict(l=40, r=40, t=40, b=40),  # Adjust margins: left, right, top, bottom\n",
    "    boxmode='group',  # Ensure boxes do not overlap\n",
    "    yaxis=dict(\n",
    "        range=[df_superpose['PM_2.5'].quantile(0.05), df_superpose['PM_2.5'].quantile(0.95)]  # Limit y-axis to 5-95% of data\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626cccb3-5fe2-401d-8b52-8aa7cc8b8469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average per hour and per station\n",
    "mean_values = df_superpose.groupby(['hour', 'sensor_name'])['PM_2.5'].mean().reset_index()\n",
    "\n",
    "# Remove a specific station if needed\n",
    "mean_values = mean_values[mean_values['sensor_name'] != 'standalone-LOPY-AQ05']\n",
    "\n",
    "# Create the plot with Plotly\n",
    "fig = px.line(mean_values, \n",
    "              x='hour', \n",
    "              y='PM_2.5', \n",
    "              color='sensor_name',\n",
    "              title=\"Average v (ug/m³) by hour and station\",\n",
    "              labels={\n",
    "                  \"hour\": \"Hour of the Day\",\n",
    "                  \"v (ug/m3)\": \"Pollution (µg/m³)\",\n",
    "                  \"sensor_name\": \"Station\"\n",
    "              })\n",
    "\n",
    "# Display the plot\n",
    "fig.update_layout(legend_title_text='Station',\n",
    "                  legend=dict(x=1.05, y=0.5),\n",
    "                  margin=dict(r=150))  # offset to make space for the legend\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efecbe07-4936-4f76-bb36-05377234fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the order of the days of the week\n",
    "order_days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "df_superpose['day_week'] = pd.Categorical(df_superpose['day_week'], categories=order_days, ordered=True)\n",
    "\n",
    "# Calculate the average value per day of the week and per station\n",
    "mean_values = df_superpose.groupby(['day_week', 'sensor_name'], observed=True)['PM_2.5'].mean().reset_index()\n",
    "\n",
    "# Create the plot with Plotly\n",
    "fig = px.line(\n",
    "    mean_values,\n",
    "    x='day_week',\n",
    "    y='PM_2.5',\n",
    "    color='sensor_name',\n",
    "    markers=True,\n",
    "    title=\"Average PM_2.5 (ug/m³) by Day of the Week and Station\",\n",
    "    labels={'day_week': 'Day of the Week', 'PM_2.5': 'Concentration (µg/m³)', 'sensor_name': 'Station'}\n",
    ")\n",
    "\n",
    "# Display the legend on the right\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        title='Station',\n",
    "        orientation=\"v\",\n",
    "        yanchor=\"middle\",\n",
    "        y=0.5,\n",
    "        xanchor=\"left\",\n",
    "        x=1\n",
    "    ),\n",
    "    margin=dict(r=150)  # to prevent cutting off the legend\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa4de2-9146-44f7-9453-286de81d6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the order of the days of the week\n",
    "order_days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "df_superpose['day_week'] = pd.Categorical(df_superpose['day_week'], categories=order_days, ordered=True)\n",
    "\n",
    "# Calculate the average PM_2.5 per day of the week (all stations combined)\n",
    "mean_values = df_superpose.groupby('day_week', observed=True)['PM_2.5'].mean().reset_index()\n",
    "\n",
    "# Create the plot with Plotly (no color grouping)\n",
    "fig = px.line(\n",
    "    mean_values,\n",
    "    x='day_week',\n",
    "    y='PM_2.5',\n",
    "    markers=True,\n",
    "    title=\"Average PM_2.5 (µg/m³) by Day of the Week (All Stations Combined)\",\n",
    "    labels={'day_week': 'Day of the Week', 'PM_2.5': 'Concentration (µg/m³)'}\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc926f1-d264-4aca-a05a-9e4b46a9f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the global daily average (all stations)\n",
    "global_mean = df_superpose.groupby(df_superpose['measure_date'].dt.date)['PM_2.5'].mean().reset_index()\n",
    "global_mean.columns = ['date', 'mean_v']\n",
    "\n",
    "# Add smoothed average\n",
    "global_mean['smoothed_mean'] = global_mean['mean_v'].rolling(window=7, center=True).mean()\n",
    "\n",
    "# Calculate the number of measurements per day\n",
    "count_by_day = df_superpose.groupby(df_superpose['measure_date'].dt.date)['PM_2.5'].count().reset_index()\n",
    "count_by_day.columns = ['date', 'count']\n",
    "global_mean = global_mean.merge(count_by_day, on='date')\n",
    "\n",
    "# Create the plot\n",
    "fig = px.line(\n",
    "    global_mean,\n",
    "    x='date',\n",
    "    y='mean_v',\n",
    "    markers=True,\n",
    "    custom_data=['count'],\n",
    "    title=\"Daily Average of PM_2.5 (ug/m³)\",\n",
    "    labels={\n",
    "        'mean_v': 'Concentration (µg/m³)',\n",
    "        'date': 'Date',\n",
    "        'count': 'Number of Measurements'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Name the trace\n",
    "fig.update_traces(name='Raw Average')\n",
    "\n",
    "# Target this trace specifically\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"<br>\".join([\n",
    "        \"Date: %{x}\",\n",
    "        \"Average: %{y:.2f} µg/m³\",\n",
    "        \"Number of Measurements: %{customdata[0]}\"\n",
    "    ]),\n",
    "    selector=dict(name='Raw Average')\n",
    ")\n",
    "\n",
    "# Add the smoothed line\n",
    "fig.add_scatter(\n",
    "    x=global_mean['date'],\n",
    "    y=global_mean['smoothed_mean'],\n",
    "    mode='lines',\n",
    "    name='Smoothed Average (7 days)',\n",
    "    line=dict(color='black', width=3)\n",
    ")\n",
    "\n",
    "# Set color for the main line\n",
    "fig.update_traces(line_color='darkorange', line_width=3, selector=dict(name=None))\n",
    "fig.update_layout(hovermode='x unified')\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
